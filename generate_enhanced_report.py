import json
import csv
from datetime import datetime
from collections import defaultdict

OUTPUT_DIR = "analysis_output"


def load_trading_decisions():
    """åŠ è½½äº¤æ˜“å†³ç­–æ•°æ®"""
    with open(f"{OUTPUT_DIR}/trading_decisions.json", "r", encoding="utf-8") as f:
        return json.load(f)


def load_position_changes_csv():
    """åŠ è½½CSVæ•°æ®"""
    changes = []
    with open(f"{OUTPUT_DIR}/position_changes.csv", "r", encoding="utf-8") as f:
        reader = csv.DictReader(f)
        for row in reader:
            changes.append(row)
    return changes


def extract_key_decisions(model_id, decisions):
    """æå–æŒ‡å®šæ¨¡å‹çš„å…³é”®å†³ç­–"""
    model_decisions = [d for d in decisions if d["model_id"] == model_id]

    # æŒ‰æ—¶é—´æ’åº
    model_decisions.sort(key=lambda x: x["timestamp"])

    return model_decisions


def format_decision_timeline(decisions):
    """æ ¼å¼åŒ–å†³ç­–æ—¶é—´çº¿"""
    lines = []

    for idx, decision in enumerate(decisions, 1):
        cycle = decision["cycle_id"]
        change_type = decision["change_type"]
        coin = decision["coin"]
        prev_qty = decision["prev_quantity"]
        new_qty = decision["new_quantity"]
        leverage = decision.get("leverage", "N/A")
        account_value = decision["account_value"]
        return_pct = decision["return_pct"]

        # æ“ä½œç±»å‹ä¸­æ–‡
        action_map = {
            "open_long": f"å¼€ä»“åšå¤š {coin}",
            "open_short": f"å¼€ä»“åšç©º {coin}",
            "close_long": f"å¹³ä»“(å¤šå¤´) {coin}",
            "close_short": f"å¹³ä»“(ç©ºå¤´) {coin}",
            "add_position": f"åŠ ä»“ {coin}",
            "reduce_position": f"å‡ä»“ {coin}",
            "flip_position": f"ç¿»è½¬ {coin}",
        }
        action_title = action_map.get(change_type, change_type)

        lines.append(f"\n###### {idx}. Cycle {cycle}: {action_title}\n")

        if "open" in change_type:
            direction = "åšå¤š" if "long" in change_type else "åšç©º"
            lines.append(
                f"- **æ“ä½œ**: {direction} {abs(new_qty):.2f} @ {leverage}xæ æ†\n"
            )
        elif "close" in change_type:
            lines.append(f"- **æ“ä½œ**: å¹³ä»“ {abs(prev_qty):.2f}\n")
        else:
            lines.append(f"- **æ“ä½œ**: {abs(prev_qty):.2f} â†’ {abs(new_qty):.2f}\n")

        lines.append(
            f"- **è´¦æˆ·çŠ¶æ€**: ${account_value:,.2f} (æ”¶ç›Šç‡: {return_pct:.2f}%)\n"
        )

        # å†³ç­–æ‘˜è¦
        summary = decision.get("cot_trace_summary", "")
        if summary:
            lines.append(f"\n**ç­–ç•¥æ€è€ƒ**:\n> {summary}\n")

        # ä»å®Œæ•´traceä¸­æå–å…³é”®ä¿¡æ¯
        cot_trace = decision.get("cot_trace", "")
        key_insights = extract_key_insights(cot_trace)
        if key_insights:
            lines.append(f"\n**å†³ç­–è¦ç‚¹**:\n")
            for insight in key_insights:
                lines.append(f"- {insight}\n")

    return "".join(lines)


def extract_key_insights(cot_trace):
    """ä»æ€è€ƒè¿‡ç¨‹ä¸­æå–å…³é”®æ´å¯Ÿ"""
    if not cot_trace or not isinstance(cot_trace, str):
        return []

    insights = []

    # æ£€æµ‹æŠ€æœ¯æŒ‡æ ‡æåŠ
    if "EMA" in cot_trace.upper() or "ema" in cot_trace:
        insights.append("ğŸ” ä½¿ç”¨EMAæŠ€æœ¯æŒ‡æ ‡åˆ†æ")

    if "MACD" in cot_trace.upper():
        insights.append("ğŸ“Š å‚è€ƒMACDåŠ¨é‡æŒ‡æ ‡")

    if "RSI" in cot_trace.upper():
        insights.append("ğŸ“ˆ è€ƒè™‘RSIè¶…ä¹°è¶…å–")

    # æ£€æµ‹é£é™©ç®¡ç†
    if "stop loss" in cot_trace.lower() or "stop-loss" in cot_trace.lower():
        insights.append("ğŸ›¡ï¸ è®¾ç½®æ­¢æŸä¿æŠ¤")

    if "risk" in cot_trace.lower():
        insights.append("âš ï¸ å…³æ³¨é£é™©ç®¡ç†")

    # æ£€æµ‹å¸‚åœºåˆ¤æ–­
    if "bullish" in cot_trace.lower():
        insights.append("ğŸ“ˆ åˆ¤æ–­å¸‚åœºçœ‹æ¶¨")
    elif "bearish" in cot_trace.lower():
        insights.append("ğŸ“‰ åˆ¤æ–­å¸‚åœºçœ‹è·Œ")

    # æ£€æµ‹æŒä»“ç­–ç•¥
    if "hold" in cot_trace.lower() and "ing" in cot_trace.lower():
        insights.append("ğŸ’ åšæŒæŒæœ‰ç­–ç•¥")

    if "overtrading" in cot_trace.lower():
        insights.append("ğŸš« é¿å…è¿‡åº¦äº¤æ˜“")

    return insights[:5]  # æœ€å¤šè¿”å›5ä¸ªå…³é”®ç‚¹


def analyze_decision_pattern(decisions):
    """åˆ†æå†³ç­–æ¨¡å¼"""
    if not decisions:
        return ""

    lines = []
    lines.append("\n#### å†³ç­–æ¨¡å¼åˆ†æ\n\n")

    # ç»Ÿè®¡
    total_trades = len(decisions)
    open_trades = len([d for d in decisions if "open" in d["change_type"]])
    close_trades = len([d for d in decisions if "close" in d["change_type"]])
    long_trades = len([d for d in decisions if "long" in d["change_type"]])
    short_trades = len([d for d in decisions if "short" in d["change_type"]])

    lines.append(f"**äº¤æ˜“ç»Ÿè®¡**:\n")
    lines.append(f"- æ€»äº¤æ˜“æ¬¡æ•°: {total_trades}\n")
    lines.append(f"- å¼€ä»“æ¬¡æ•°: {open_trades}\n")
    lines.append(f"- å¹³ä»“æ¬¡æ•°: {close_trades}\n")
    lines.append(f"- åšå¤šæ¬¡æ•°: {long_trades}\n")
    lines.append(f"- åšç©ºæ¬¡æ•°: {short_trades}\n\n")

    # äº¤æ˜“é£æ ¼
    lines.append(f"**äº¤æ˜“é£æ ¼**:\n")
    if total_trades <= 2:
        lines.append(f"- ğŸ“‰ **æä½é¢‘äº¤æ˜“**: é«˜åº¦ä¸“æ³¨ï¼Œé•¿æœŸæŒæœ‰\n")
    elif total_trades <= 5:
        lines.append(f"- ğŸ“Š **ä½é¢‘äº¤æ˜“**: é€‰æ‹©æ€§è¿›åœºï¼Œæ³¨é‡è´¨é‡\n")
    elif total_trades <= 10:
        lines.append(f"- ğŸ“ˆ **ä¸­é¢‘äº¤æ˜“**: é€‚åº¦æ´»è·ƒï¼Œå¹³è¡¡è¿›å‡º\n")
    else:
        lines.append(f"- ğŸ”„ **é«˜é¢‘äº¤æ˜“**: é¢‘ç¹è°ƒæ•´ï¼Œç§¯ææ“ä½œ\n")

    if long_trades > 0 and short_trades > 0:
        lines.append(f"- âš–ï¸ **å¤šç©ºåŒå‘**: åŒæ—¶ä½¿ç”¨å¤šå¤´å’Œç©ºå¤´ç­–ç•¥\n")
    elif long_trades > 0:
        lines.append(f"- ğŸ“ˆ **çº¯å¤šå¤´**: ä»…åšå¤šï¼Œé¡ºåŠ¿äº¤æ˜“\n")
    elif short_trades > 0:
        lines.append(f"- ğŸ“‰ **çº¯ç©ºå¤´**: ä»…åšç©ºï¼Œé€†åŠ¿æˆ–å¯¹å†²\n")

    # æŒä»“æ—¶é•¿
    if len(decisions) >= 2:
        first_trade = decisions[0]
        last_trade = decisions[-1]
        duration_cycles = last_trade["cycle_id"] - first_trade["cycle_id"]
        lines.append(f"- â±ï¸ **æ´»è·ƒå‘¨æœŸ**: {duration_cycles} cycles\n")

    return "".join(lines)


def generate_enhanced_report():
    """ç”Ÿæˆå¢å¼ºç‰ˆæŠ¥å‘Š"""
    print("ç”Ÿæˆå¢å¼ºç‰ˆäº¤æ˜“åˆ†ææŠ¥å‘Š...")

    # åŠ è½½æ•°æ®
    decisions = load_trading_decisions()

    # é‡ç‚¹æ¨¡å‹
    key_models = {
        "qwen3-max": "ç›ˆåˆ©å† å†› +42.89%",
        "deepseek-chat-v3.1": "ç›ˆåˆ©äºšå†› +26.82%",
        "gpt-5": "æœ€å¤§äºæŸ -72.93%",
        "gemini-2.5-pro": "ç¬¬äºŒå¤§äºæŸ -63.49%",
    }

    report_path = f"{OUTPUT_DIR}/TRADING_ANALYSIS_REPORT.md"

    # è¯»å–ç°æœ‰æŠ¥å‘Š
    with open(report_path, "r", encoding="utf-8") as f:
        existing_report = f.read()

    # ä¸ºæ¯ä¸ªé‡ç‚¹æ¨¡å‹ç”Ÿæˆè¯¦ç»†åˆ†æ
    enhanced_sections = {}

    for model_id, label in key_models.items():
        print(f"  åˆ†æ {model_id}...")

        model_decisions = extract_key_decisions(model_id, decisions)

        section = []
        section.append(f"\n#### äº¤æ˜“å†³ç­–æ—¶é—´çº¿\n")

        if model_decisions:
            timeline = format_decision_timeline(model_decisions)
            section.append(timeline)

            pattern = analyze_decision_pattern(model_decisions)
            section.append(pattern)
        else:
            section.append(f"\n*åœ¨æ•°æ®é‡‡é›†æœŸé—´æœªæ£€æµ‹åˆ°æ˜æ˜¾çš„æŒä»“å˜åŒ–*\n")

        enhanced_sections[model_id] = "".join(section)

    # æ’å…¥å¢å¼ºå†…å®¹åˆ°æŠ¥å‘Šä¸­
    enhanced_report = existing_report

    # ä¸ºæ¯ä¸ªæ¨¡å‹æ·»åŠ æ–°ç« èŠ‚
    for model_id, content in enhanced_sections.items():
        # æ‰¾åˆ°è¯¥æ¨¡å‹çš„ç« èŠ‚ï¼Œåœ¨"å…³é”®æ‹ç‚¹åˆ†æ"ä¹‹åæ’å…¥
        marker = f"### {model_id} -"
        if marker in enhanced_report:
            # æ‰¾åˆ°ä¸‹ä¸€ä¸ª "---" çš„ä½ç½®
            start_pos = enhanced_report.find(marker)
            end_marker = "\n---\n"
            end_pos = enhanced_report.find(end_marker, start_pos)

            if end_pos != -1:
                # åœ¨ "---" ä¹‹å‰æ’å…¥æ–°å†…å®¹
                enhanced_report = (
                    enhanced_report[:end_pos] + content + enhanced_report[end_pos:]
                )

    # ä¿å­˜å¢å¼ºæŠ¥å‘Š
    with open(report_path, "w", encoding="utf-8") as f:
        f.write(enhanced_report)

    print(f"[OK] å¢å¼ºæŠ¥å‘Šå·²ä¿å­˜: {report_path}")


def generate_decision_patterns_doc():
    """ç”Ÿæˆå†³ç­–æ¨¡å¼ä¸“é¢˜æ–‡æ¡£"""
    print("\nç”Ÿæˆå†³ç­–æ¨¡å¼ä¸“é¢˜åˆ†æ...")

    decisions = load_trading_decisions()

    output_path = f"{OUTPUT_DIR}/DECISION_PATTERNS.md"

    with open(output_path, "w", encoding="utf-8") as f:
        f.write("# AIäº¤æ˜“æ¨¡å‹å†³ç­–æ¨¡å¼æ·±åº¦åˆ†æ\n\n")
        f.write(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        f.write("---\n\n")

        f.write("## æ¦‚è¿°\n\n")
        f.write(
            f"æœ¬æ–‡æ¡£æ·±å…¥åˆ†æäº†6ä¸ªAIäº¤æ˜“æ¨¡å‹çš„æ‰€æœ‰äº¤æ˜“å†³ç­–ï¼Œå…±æ£€æµ‹åˆ°**{len(decisions)}ä¸ªæŒä»“å˜åŒ–**ã€‚\n\n"
        )

        # æŒ‰æ¨¡å‹åˆ†ç»„
        model_groups = defaultdict(list)
        for d in decisions:
            model_groups[d["model_id"]].append(d)

        # ç”Ÿæˆå„æ¨¡å‹è¯¦ç»†åˆ†æ
        for model_id in sorted(model_groups.keys()):
            model_decisions = model_groups[model_id]

            f.write(f"---\n\n## {model_id}\n\n")
            f.write(f"**æ€»äº¤æ˜“æ¬¡æ•°**: {len(model_decisions)}\n\n")

            # å†³ç­–æ—¶é—´çº¿
            f.write("### å®Œæ•´äº¤æ˜“è®°å½•\n")
            timeline = format_decision_timeline(model_decisions)
            f.write(timeline)

            # æ¨¡å¼åˆ†æ
            pattern = analyze_decision_pattern(model_decisions)
            f.write(pattern)

    print(f"[OK] å†³ç­–æ¨¡å¼æ–‡æ¡£å·²ä¿å­˜: {output_path}")


def main():
    print("=" * 60)
    print("ç”Ÿæˆå¢å¼ºåˆ†ææŠ¥å‘Š")
    print("=" * 60)

    # ç”Ÿæˆå¢å¼ºæŠ¥å‘Š
    generate_enhanced_report()

    # ç”Ÿæˆå†³ç­–æ¨¡å¼æ–‡æ¡£
    generate_decision_patterns_doc()

    print("\n" + "=" * 60)
    print("[SUCCESS] æ‰€æœ‰æŠ¥å‘Šç”Ÿæˆå®Œæˆï¼")
    print("=" * 60)


if __name__ == "__main__":
    main()
