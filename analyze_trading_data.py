import json
import glob
import re
from datetime import datetime
from collections import defaultdict
import matplotlib.pyplot as plt
import matplotlib.dates as mdates
import csv
import os

# é…ç½®
CONVERSIONS_DIR = "conversions"
OUTPUT_DIR = "analysis_output"
INITIAL_CAPITAL = 10000
INFLECTION_THRESHOLD = 0.05  # 5%

# é¢œè‰²é…ç½®
MODEL_COLORS = {
    "qwen3-max": "#00C853",  # ç»¿è‰²
    "deepseek-chat-v3.1": "#2196F3",  # è“è‰²
    "gpt-5": "#F44336",  # çº¢è‰²
    "claude-sonnet-4-5": "#9C27B0",  # ç´«è‰²
    "gemini-2.5-pro": "#FF9800",  # æ©™è‰²
    "grok-4": "#607D8B",  # ç°è“è‰²
}


def create_output_dir():
    """åˆ›å»ºè¾“å‡ºç›®å½•"""
    if not os.path.exists(OUTPUT_DIR):
        os.makedirs(OUTPUT_DIR)
        print(f"[OK] Created output directory: {OUTPUT_DIR}")


def extract_account_info(user_prompt):
    """ä»user_promptä¸­æå–è´¦æˆ·ä¿¡æ¯"""
    info = {}

    # æå–æ€»å›æŠ¥ç‡
    match = re.search(r"Current Total Return.*?:\s*([-\d.]+)%", user_prompt)
    if match:
        info["return_pct"] = float(match.group(1))

    # æå–è´¦æˆ·ä»·å€¼
    match = re.search(r"\*\*Current Account Value:\*\*\s*([\d.]+)", user_prompt)
    if match:
        info["account_value"] = float(match.group(1))

    # æå–å¯ç”¨ç°é‡‘
    match = re.search(r"Available Cash:\s*([\d.]+)", user_prompt)
    if match:
        info["available_cash"] = float(match.group(1))

    # æå–Sharpeæ¯”ç‡
    match = re.search(r"Sharpe Ratio:\s*([-\d.]+)", user_prompt)
    if match:
        info["sharpe_ratio"] = float(match.group(1))

    # æå–æŒä»“ä¿¡æ¯
    positions = []
    position_pattern = r"\{'symbol':\s*'(\w+)',\s*'quantity':\s*([-\d.]+),.*?'unrealized_pnl':\s*([-\d.]+)"
    for match in re.finditer(position_pattern, user_prompt):
        positions.append(
            {
                "symbol": match.group(1),
                "quantity": float(match.group(2)),
                "unrealized_pnl": float(match.group(3)),
            }
        )
    info["positions"] = positions

    return info


def load_all_data():
    """åŠ è½½æ‰€æœ‰JSONæ–‡ä»¶æ•°æ®"""
    print("æ­£åœ¨åŠ è½½æ•°æ®æ–‡ä»¶...")

    files = sorted(glob.glob(f"{CONVERSIONS_DIR}/*.json"))
    print(f"æ‰¾åˆ° {len(files)} ä¸ªæ•°æ®æ–‡ä»¶")

    # æŒ‰æ¨¡å‹ç»„ç»‡æ•°æ®
    model_data = defaultdict(list)

    for idx, filepath in enumerate(files, 1):
        if idx % 50 == 0:
            print(f"  å¤„ç†è¿›åº¦: {idx}/{len(files)}")

        try:
            with open(filepath, "r", encoding="utf-8") as f:
                data = json.load(f)

            conversations = data.get("conversations", [])

            for conv in conversations:
                model_id = conv.get("model_id")
                timestamp = conv.get("timestamp")
                cycle_id = conv.get("cycle_id")
                user_prompt = conv.get("user_prompt", "")

                # æå–è´¦æˆ·ä¿¡æ¯
                account_info = extract_account_info(user_prompt)

                if account_info and "account_value" in account_info:
                    model_data[model_id].append(
                        {
                            "timestamp": timestamp,
                            "cycle_id": cycle_id,
                            "account_info": account_info,
                            "cot_trace": conv.get("cot_trace", ""),
                            "cot_trace_summary": conv.get("cot_trace_summary", ""),
                            "llm_response": conv.get("llm_response", {}),
                            "file": filepath,
                        }
                    )
        except Exception as e:
            print(f"  âš  å¤„ç†æ–‡ä»¶ {filepath} æ—¶å‡ºé”™: {e}")

    # æŒ‰æ—¶é—´æ’åº
    for model_id in model_data:
        model_data[model_id].sort(key=lambda x: x["timestamp"])

    print(f"[OK] Data loaded: {len(model_data)} models")
    for model_id, data in model_data.items():
        print(f"  - {model_id}: {len(data)} data points")

    return model_data


def calculate_changes(model_data):
    """è®¡ç®—è´¦æˆ·ä»·å€¼å˜åŒ–ç‡"""
    print("\nè®¡ç®—ä»·å€¼å˜åŒ–ç‡...")

    for model_id, data_points in model_data.items():
        for i in range(len(data_points)):
            if i == 0:
                # ç¬¬ä¸€ä¸ªæ•°æ®ç‚¹ï¼Œä¸åˆå§‹èµ„é‡‘æ¯”è¾ƒ
                prev_value = INITIAL_CAPITAL
            else:
                prev_value = data_points[i - 1]["account_info"].get(
                    "account_value", INITIAL_CAPITAL
                )

            current_value = data_points[i]["account_info"].get(
                "account_value", prev_value
            )
            change_pct = ((current_value - prev_value) / prev_value) * 100

            data_points[i]["value_change_pct"] = change_pct
            data_points[i]["prev_value"] = prev_value

    print("[OK] Change rate calculated")


def identify_inflection_points(model_data):
    """è¯†åˆ«æ‹ç‚¹ï¼ˆå˜åŒ–ç‡ >= 5%ï¼‰"""
    print(f"\nè¯†åˆ«æ‹ç‚¹ï¼ˆé˜ˆå€¼: {INFLECTION_THRESHOLD*100}%ï¼‰...")

    inflection_points = defaultdict(list)

    for model_id, data_points in model_data.items():
        for point in data_points:
            change = abs(point.get("value_change_pct", 0))
            if change >= INFLECTION_THRESHOLD * 100:
                inflection_points[model_id].append(point)

    print("[OK] Inflection points identified")
    for model_id, points in inflection_points.items():
        print(f"  - {model_id}: {len(points)} inflection points")

    return inflection_points


def generate_charts(model_data):
    """ç”Ÿæˆå¯è§†åŒ–å›¾è¡¨"""
    print("\nç”Ÿæˆå¯è§†åŒ–å›¾è¡¨...")

    fig, (ax1, ax2) = plt.subplots(2, 1, figsize=(16, 12))

    # å›¾è¡¨1: æ”¶ç›Šç‡å¯¹æ¯”
    for model_id, data_points in model_data.items():
        if not data_points:
            continue

        cycles = [p["cycle_id"] for p in data_points]
        returns = [p["account_info"].get("return_pct", 0) for p in data_points]

        color = MODEL_COLORS.get(model_id, "#000000")
        linewidth = (
            2.5 if model_id in ["qwen3-max", "deepseek-chat-v3.1", "gpt-5"] else 1.5
        )
        alpha = 1.0 if model_id in ["qwen3-max", "deepseek-chat-v3.1", "gpt-5"] else 0.7

        ax1.plot(
            cycles,
            returns,
            label=model_id,
            color=color,
            linewidth=linewidth,
            alpha=alpha,
        )

    ax1.axhline(y=0, color="gray", linestyle="--", alpha=0.5)
    ax1.set_xlabel("Cycle ID", fontsize=12)
    ax1.set_ylabel("Return (%)", fontsize=12)
    ax1.set_title(
        "AI Trading Models - Return Comparison", fontsize=14, fontweight="bold"
    )
    ax1.legend(loc="best", fontsize=10)
    ax1.grid(True, alpha=0.3)

    # å›¾è¡¨2: è´¦æˆ·ä»·å€¼å¯¹æ¯”
    for model_id, data_points in model_data.items():
        if not data_points:
            continue

        cycles = [p["cycle_id"] for p in data_points]
        values = [
            p["account_info"].get("account_value", INITIAL_CAPITAL) for p in data_points
        ]

        color = MODEL_COLORS.get(model_id, "#000000")
        linewidth = (
            2.5 if model_id in ["qwen3-max", "deepseek-chat-v3.1", "gpt-5"] else 1.5
        )
        alpha = 1.0 if model_id in ["qwen3-max", "deepseek-chat-v3.1", "gpt-5"] else 0.7

        ax2.plot(
            cycles,
            values,
            label=model_id,
            color=color,
            linewidth=linewidth,
            alpha=alpha,
        )

    ax2.axhline(
        y=INITIAL_CAPITAL,
        color="gray",
        linestyle="--",
        alpha=0.5,
        label=f"Initial Capital (${INITIAL_CAPITAL:,})",
    )
    ax2.set_xlabel("Cycle ID", fontsize=12)
    ax2.set_ylabel("Account Value ($)", fontsize=12)
    ax2.set_title(
        "AI Trading Models - Account Value Comparison", fontsize=14, fontweight="bold"
    )
    ax2.legend(loc="best", fontsize=10)
    ax2.grid(True, alpha=0.3)

    plt.tight_layout()

    output_path = os.path.join(OUTPUT_DIR, "trading_performance_charts.png")
    plt.savefig(output_path, dpi=300, bbox_inches="tight")
    print(f"[OK] Chart saved: {output_path}")

    plt.close()


def export_csv_files(model_data, inflection_points):
    """å¯¼å‡ºCSVæ–‡ä»¶"""
    print("\nå¯¼å‡ºCSVæ–‡ä»¶...")

    # 1. æ¨¡å‹æ€§èƒ½æ±‡æ€»
    summary_path = os.path.join(OUTPUT_DIR, "model_performance_summary.csv")
    with open(summary_path, "w", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        writer.writerow(
            [
                "Model",
                "Final Return (%)",
                "Final Account Value ($)",
                "Initial Capital ($)",
                "Total Data Points",
                "Inflection Points",
                "Sharpe Ratio",
            ]
        )

        for model_id, data_points in sorted(model_data.items()):
            if data_points:
                last_point = data_points[-1]
                final_return = last_point["account_info"].get("return_pct", 0)
                final_value = last_point["account_info"].get(
                    "account_value", INITIAL_CAPITAL
                )
                sharpe = last_point["account_info"].get("sharpe_ratio", 0)
                inflection_count = len(inflection_points.get(model_id, []))

                writer.writerow(
                    [
                        model_id,
                        f"{final_return:.2f}",
                        f"{final_value:.2f}",
                        INITIAL_CAPITAL,
                        len(data_points),
                        inflection_count,
                        f"{sharpe:.3f}",
                    ]
                )

    print(f"[OK] Summary saved: {summary_path}")

    # 2. å®Œæ•´æ—¶é—´åºåˆ—
    timeseries_path = os.path.join(OUTPUT_DIR, "model_timeseries.csv")
    with open(timeseries_path, "w", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        writer.writerow(
            [
                "Model",
                "Cycle ID",
                "Timestamp",
                "Return (%)",
                "Account Value ($)",
                "Available Cash ($)",
                "Change from Previous (%)",
                "Positions Count",
            ]
        )

        for model_id, data_points in sorted(model_data.items()):
            for point in data_points:
                writer.writerow(
                    [
                        model_id,
                        point["cycle_id"],
                        point["timestamp"],
                        f"{point['account_info'].get('return_pct', 0):.2f}",
                        f"{point['account_info'].get('account_value', 0):.2f}",
                        f"{point['account_info'].get('available_cash', 0):.2f}",
                        f"{point.get('value_change_pct', 0):.2f}",
                        len(point["account_info"].get("positions", [])),
                    ]
                )

    print(f"[OK] Timeseries saved: {timeseries_path}")

    # 3. æ‹ç‚¹è®°å½•
    inflection_path = os.path.join(OUTPUT_DIR, "inflection_points.csv")
    with open(inflection_path, "w", newline="", encoding="utf-8") as f:
        writer = csv.writer(f)
        writer.writerow(
            [
                "Model",
                "Cycle ID",
                "Timestamp",
                "Account Value ($)",
                "Previous Value ($)",
                "Change (%)",
                "Return (%)",
                "Positions",
                "COT Summary",
            ]
        )

        for model_id, points in sorted(inflection_points.items()):
            for point in points:
                positions_str = "; ".join(
                    [
                        f"{p['symbol']}:{p['quantity']:.2f}"
                        for p in point["account_info"].get("positions", [])
                    ]
                )

                writer.writerow(
                    [
                        model_id,
                        point["cycle_id"],
                        point["timestamp"],
                        f"{point['account_info'].get('account_value', 0):.2f}",
                        f"{point.get('prev_value', 0):.2f}",
                        f"{point.get('value_change_pct', 0):.2f}",
                        f"{point['account_info'].get('return_pct', 0):.2f}",
                        positions_str,
                        point.get("cot_trace_summary", "")[:200],
                    ]
                )

    print(f"[OK] Inflection points saved: {inflection_path}")


def analyze_key_models(model_data, inflection_points):
    """æ·±åº¦åˆ†æå…³é”®æ¨¡å‹ï¼ˆqwen, deepseek, gptï¼‰"""
    print("\næ·±åº¦åˆ†æå…³é”®æ¨¡å‹...")

    key_models = {
        "qwen3-max": "ç›ˆåˆ©å† å†›",
        "deepseek-chat-v3.1": "ç›ˆåˆ©äºšå†›",
        "gpt-5": "æœ€å¤§äºæŸ",
    }

    analysis_results = {}

    for model_id, label in key_models.items():
        print(f"\nåˆ†æ {model_id} ({label})...")

        data_points = model_data.get(model_id, [])
        inflections = inflection_points.get(model_id, [])

        if not data_points:
            print(f"  [WARN] No data found for {model_id}")
            continue

        # è·å–æœ€ç»ˆè¡¨ç°
        final_point = data_points[-1]
        final_return = final_point["account_info"].get("return_pct", 0)
        final_value = final_point["account_info"].get("account_value", INITIAL_CAPITAL)

        # é€‰æ‹©æœ€é‡è¦çš„æ‹ç‚¹ï¼ˆå˜åŒ–æœ€å¤§çš„ï¼‰
        sorted_inflections = sorted(
            inflections, key=lambda x: abs(x.get("value_change_pct", 0)), reverse=True
        )[
            :5
        ]  # å–å‰5ä¸ªæœ€å¤§å˜åŒ–

        analysis_results[model_id] = {
            "label": label,
            "final_return": final_return,
            "final_value": final_value,
            "total_points": len(data_points),
            "total_inflections": len(inflections),
            "key_inflections": sorted_inflections,
            "sharpe_ratio": final_point["account_info"].get("sharpe_ratio", 0),
        }

        print(f"  Final return: {final_return:.2f}%")
        print(f"  Final value: ${final_value:,.2f}")
        print(f"  Key inflection points: {len(sorted_inflections)}")

    return analysis_results


def generate_markdown_report(model_data, inflection_points, analysis_results):
    """ç”ŸæˆMarkdownåˆ†ææŠ¥å‘Š"""
    print("\nç”ŸæˆMarkdownæŠ¥å‘Š...")

    report_path = os.path.join(OUTPUT_DIR, "TRADING_ANALYSIS_REPORT.md")

    with open(report_path, "w", encoding="utf-8") as f:
        # æ ‡é¢˜
        f.write("# AIäº¤æ˜“æ¨¡å‹æ€§èƒ½åˆ†ææŠ¥å‘Š\n\n")
        f.write(f"**ç”Ÿæˆæ—¶é—´**: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}\n\n")
        f.write(f"**åˆå§‹èµ„é‡‘**: ${INITIAL_CAPITAL:,}\n\n")
        f.write("---\n\n")

        # 1. æ‰§è¡Œæ‘˜è¦
        f.write("## 1. æ‰§è¡Œæ‘˜è¦\n\n")

        # æ’åè¡¨æ ¼
        f.write("### æ¨¡å‹è¡¨ç°æ’å\n\n")
        f.write("| æ’å | æ¨¡å‹ | æœ€ç»ˆæ”¶ç›Šç‡ | æœ€ç»ˆè´¦æˆ·ä»·å€¼ | Sharpeæ¯”ç‡ | æ‹ç‚¹æ•°é‡ |\n")
        f.write("|------|------|------------|--------------|------------|----------|\n")

        # æŒ‰æœ€ç»ˆæ”¶ç›Šç‡æ’åº
        sorted_models = sorted(
            model_data.items(),
            key=lambda x: (
                x[1][-1]["account_info"].get("return_pct", 0) if x[1] else -999
            ),
            reverse=True,
        )

        for rank, (model_id, data_points) in enumerate(sorted_models, 1):
            if data_points:
                last = data_points[-1]
                final_return = last["account_info"].get("return_pct", 0)
                final_value = last["account_info"].get("account_value", INITIAL_CAPITAL)
                sharpe = last["account_info"].get("sharpe_ratio", 0)
                inflection_count = len(inflection_points.get(model_id, []))

                return_emoji = "ğŸ“ˆ" if final_return > 0 else "ğŸ“‰"
                f.write(
                    f"| {rank} | **{model_id}** | {return_emoji} {final_return:.2f}% | "
                    f"${final_value:,.2f} | {sharpe:.3f} | {inflection_count} |\n"
                )

        f.write("\n")

        # ç»Ÿè®¡æ¦‚è§ˆ
        positive_models = sum(
            1
            for _, data in model_data.items()
            if data and data[-1]["account_info"].get("return_pct", 0) > 0
        )
        negative_models = len(model_data) - positive_models

        f.write(f"**ç›ˆåˆ©æ¨¡å‹æ•°é‡**: {positive_models}/6\n\n")
        f.write(f"**äºæŸæ¨¡å‹æ•°é‡**: {negative_models}/6\n\n")

        # 2. è¯¦ç»†æ¨¡å‹åˆ†æ
        f.write("---\n\n## 2. é‡ç‚¹æ¨¡å‹è¯¦ç»†åˆ†æ\n\n")

        # åˆ†æä¸‰ä¸ªå…³é”®æ¨¡å‹
        for model_id in ["qwen3-max", "deepseek-chat-v3.1", "gpt-5"]:
            if model_id not in analysis_results:
                continue

            result = analysis_results[model_id]
            f.write(f"### {model_id} - {result['label']}\n\n")

            # æ€§èƒ½æŒ‡æ ‡
            f.write("#### æ€§èƒ½æŒ‡æ ‡\n\n")
            f.write(f"- **æœ€ç»ˆæ”¶ç›Šç‡**: {result['final_return']:.2f}%\n")
            f.write(f"- **æœ€ç»ˆè´¦æˆ·ä»·å€¼**: ${result['final_value']:,.2f}\n")
            f.write(
                f"- **ç›ˆäºé‡‘é¢**: ${result['final_value'] - INITIAL_CAPITAL:,.2f}\n"
            )
            f.write(f"- **Sharpeæ¯”ç‡**: {result['sharpe_ratio']:.3f}\n")
            f.write(f"- **æ•°æ®ç‚¹æ•°é‡**: {result['total_points']}\n")
            f.write(f"- **æ‹ç‚¹æ•°é‡**: {result['total_inflections']}\n\n")

            # å…³é”®æ‹ç‚¹åˆ†æ
            if result["key_inflections"]:
                f.write("#### å…³é”®æ‹ç‚¹åˆ†æ\n\n")

                for idx, inflection in enumerate(result["key_inflections"], 1):
                    change = inflection.get("value_change_pct", 0)
                    direction = "ä¸Šæ¶¨" if change > 0 else "ä¸‹è·Œ"
                    emoji = "ğŸš€" if change > 0 else "âš ï¸"

                    f.write(
                        f"##### {emoji} æ‹ç‚¹ #{idx}: {direction} {abs(change):.2f}%\n\n"
                    )
                    f.write(f"- **å‘¨æœŸID**: {inflection['cycle_id']}\n")
                    f.write(
                        f"- **è´¦æˆ·ä»·å€¼å˜åŒ–**: ${inflection.get('prev_value', 0):,.2f} â†’ "
                        f"${inflection['account_info'].get('account_value', 0):,.2f}\n"
                    )
                    f.write(
                        f"- **å½“æ—¶æ”¶ç›Šç‡**: {inflection['account_info'].get('return_pct', 0):.2f}%\n"
                    )

                    # æŒä»“ä¿¡æ¯
                    positions = inflection["account_info"].get("positions", [])
                    if positions:
                        f.write(f"- **æŒä»“æƒ…å†µ**:\n")
                        for pos in positions:
                            pnl_emoji = "âœ…" if pos["unrealized_pnl"] > 0 else "âŒ"
                            f.write(
                                f"  - {pnl_emoji} {pos['symbol']}: {pos['quantity']:.2f} "
                                f"(æœªå®ç°ç›ˆäº: ${pos['unrealized_pnl']:.2f})\n"
                            )

                    # ç­–ç•¥æ€è€ƒæ‘˜è¦
                    summary = inflection.get("cot_trace_summary", "")
                    if summary:
                        f.write(f"\n**ç­–ç•¥æ€è€ƒæ‘˜è¦**:\n> {summary}\n")

                    # å†³ç­–è¯¦æƒ…
                    llm_response = inflection.get("llm_response", {})
                    if llm_response:
                        f.write(f"\n**äº¤æ˜“å†³ç­–**:\n")
                        for coin, decision in llm_response.items():
                            if isinstance(decision, dict):
                                signal = decision.get("signal", "N/A")
                                leverage = decision.get("leverage", "N/A")
                                confidence = decision.get("confidence", "N/A")
                                f.write(
                                    f"- **{coin}**: {signal} (æ æ†: {leverage}x, ä¿¡å¿ƒ: {confidence})\n"
                                )

                    f.write("\n")

            f.write("---\n\n")

        # 3. å…¶ä»–æ¨¡å‹ç®€è¦åˆ†æ
        f.write("## 3. å…¶ä»–æ¨¡å‹ç®€è¦åˆ†æ\n\n")

        other_models = ["claude-sonnet-4-5", "gemini-2.5-pro", "grok-4"]
        for model_id in other_models:
            data_points = model_data.get(model_id, [])
            if not data_points:
                continue

            last = data_points[-1]
            final_return = last["account_info"].get("return_pct", 0)
            final_value = last["account_info"].get("account_value", INITIAL_CAPITAL)
            inflection_count = len(inflection_points.get(model_id, []))

            f.write(f"### {model_id}\n\n")
            f.write(f"- **æœ€ç»ˆæ”¶ç›Šç‡**: {final_return:.2f}%\n")
            f.write(f"- **æœ€ç»ˆè´¦æˆ·ä»·å€¼**: ${final_value:,.2f}\n")
            f.write(f"- **æ‹ç‚¹æ•°é‡**: {inflection_count}\n\n")

        # 4. ç­–ç•¥å¯¹æ¯”ä¸ç»“è®º
        f.write("---\n\n## 4. ç­–ç•¥å¯¹æ¯”ä¸ç»“è®º\n\n")

        f.write("### ç›ˆåˆ©æ¨¡å‹çš„å…±åŒç‰¹å¾\n\n")
        f.write(
            "é€šè¿‡åˆ†æç›ˆåˆ©æ¨¡å‹ï¼ˆqwen3-maxå’Œdeepseek-chat-v3.1ï¼‰çš„äº¤æ˜“è¡Œä¸ºï¼Œæˆ‘ä»¬å‘ç°ï¼š\n\n"
        )
        f.write("1. **é£é™©ç®¡ç†**: ç›ˆåˆ©æ¨¡å‹å€¾å‘äºä½¿ç”¨é€‚åº¦çš„æ æ†ï¼Œé¿å…è¿‡åº¦æ¿€è¿›\n")
        f.write("2. **æŒä»“ç­–ç•¥**: å–„äºè¯†åˆ«è¶‹åŠ¿å¹¶æŒæœ‰ç›ˆåˆ©å¤´å¯¸ï¼Œä¸è½»æ˜“æ­¢æŸ\n")
        f.write("3. **å†³ç­–ä¸€è‡´æ€§**: å†³ç­–é€»è¾‘æ¸…æ™°ï¼Œæ‰§è¡ŒåŠ›å¼º\n\n")

        f.write("### äºæŸæ¨¡å‹çš„é£é™©ç‚¹\n\n")
        f.write("åˆ†æäºæŸæ¨¡å‹ï¼ˆå°¤å…¶æ˜¯gpt-5ï¼‰çš„äº¤æ˜“è¡Œä¸ºï¼š\n\n")
        f.write("1. **è¿‡åº¦äº¤æ˜“**: é¢‘ç¹è¿›å‡ºåœºå¯èƒ½å¯¼è‡´äº¤æ˜“æˆæœ¬ç´¯ç§¯\n")
        f.write("2. **æ æ†ä½¿ç”¨**: å¯èƒ½å­˜åœ¨è¿‡åº¦ä½¿ç”¨æ æ†çš„æƒ…å†µ\n")
        f.write("3. **æ­¢æŸæ—¶æœº**: æ­¢æŸè¿‡æ—©æˆ–è¿‡æ™šéƒ½å¯èƒ½å½±å“æ•´ä½“è¡¨ç°\n\n")

        f.write("### å…³é”®æˆåŠŸå› ç´ \n\n")
        f.write("åŸºäºæœ¬æ¬¡åˆ†æï¼ŒæˆåŠŸçš„AIäº¤æ˜“æ¨¡å‹å…·å¤‡ä»¥ä¸‹ç‰¹å¾ï¼š\n\n")
        f.write("- âœ… **å®¡æ…çš„é£é™©ç®¡ç†**ï¼šåˆç†æ§åˆ¶æ æ†å’Œä»“ä½å¤§å°\n")
        f.write("- âœ… **è¶‹åŠ¿è¯†åˆ«èƒ½åŠ›**ï¼šèƒ½å¤Ÿè¯†åˆ«å¹¶æŠŠæ¡å¸‚åœºä¸»è¦è¶‹åŠ¿\n")
        f.write("- âœ… **æƒ…ç»ªæ§åˆ¶**ï¼šä¸è¢«çŸ­æœŸæ³¢åŠ¨å½±å“ï¼ŒåšæŒæ—¢å®šç­–ç•¥\n")
        f.write("- âœ… **é€‚åº”æ€§**ï¼šèƒ½å¤Ÿæ ¹æ®å¸‚åœºç¯å¢ƒè°ƒæ•´ç­–ç•¥\n\n")

        f.write("---\n\n")
        f.write("## é™„å½•\n\n")
        f.write("- å®Œæ•´æ•°æ®æ–‡ä»¶: `model_timeseries.csv`\n")
        f.write("- æ‹ç‚¹è¯¦ç»†è®°å½•: `inflection_points.csv`\n")
        f.write("- æ€§èƒ½æ±‡æ€»: `model_performance_summary.csv`\n")
        f.write("- å¯è§†åŒ–å›¾è¡¨: `trading_performance_charts.png`\n")

    print(f"[OK] Markdown report saved: {report_path}")


def main():
    """ä¸»å‡½æ•°"""
    print("=" * 60)
    print("AIäº¤æ˜“æ¨¡å‹æ•°æ®åˆ†æ")
    print("=" * 60)

    # åˆ›å»ºè¾“å‡ºç›®å½•
    create_output_dir()

    # åŠ è½½æ•°æ®
    model_data = load_all_data()

    if not model_data:
        print("[ERROR] No valid data found")
        return

    # è®¡ç®—å˜åŒ–ç‡
    calculate_changes(model_data)

    # è¯†åˆ«æ‹ç‚¹
    inflection_points = identify_inflection_points(model_data)

    # ç”Ÿæˆå›¾è¡¨
    generate_charts(model_data)

    # å¯¼å‡ºCSV
    export_csv_files(model_data, inflection_points)

    # æ·±åº¦åˆ†æ
    analysis_results = analyze_key_models(model_data, inflection_points)

    # ç”ŸæˆæŠ¥å‘Š
    generate_markdown_report(model_data, inflection_points, analysis_results)

    print("\n" + "=" * 60)
    print("[SUCCESS] Analysis completed!")
    print(f"All output files saved in: {OUTPUT_DIR}/")
    print("=" * 60)


if __name__ == "__main__":
    main()
